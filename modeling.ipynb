{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import neptune\n",
    "import pandas as pd\n",
    "\n",
    "from cv import get_indices\n",
    "from load_data import load\n",
    "from model_selection import training\n",
    "import random\n",
    "from NN import simple_torchpl\n",
    "from pl_framework import nn_training\n",
    "from pytorch_forecasting.metrics import MAPE\n",
    "import torch\n",
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Необходимо указать данные для авторизации в neptune проекте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neptune.init('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['NEPTUNE_API_TOKEN']=\n",
    "os.environ['NEPTUNE_PROJECT']=\n",
    "os.environ['NEPTUNE_NOTEBOOK_ID']=\n",
    "os.environ['NEPTUNE_NOTEBOOK_PATH']="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = 'data/'\n",
    "random_state = 54321"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_features, train_targets, _ = load(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv = get_indices(train_targets, \n",
    "                 [(pd.to_datetime('2020-03-01 00:00:00'), pd.to_datetime('2020-03-15 00:00:00')),\n",
    "                  (pd.to_datetime('2020-03-15 00:00:00'), pd.to_datetime('2020-03-31 00:00:00')),\n",
    "                  (pd.to_datetime('2020-03-31 00:00:00'), pd.to_datetime('2020-04-15 00:00:00'))\n",
    "                 ],\n",
    "                 first_train = True\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подбор модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "for loss in ['MSE', 'MAE', 'MAPE']:\n",
    "    for target in ['B_C2H6', 'B_C3H8', 'B_iC4H10', 'B_nC4H10']:\n",
    "        my_training = training(name = target, nn_model = simple_torchpl, training_nn = nn_training,\n",
    "                               description = 'Ffill. New train for each fold. Simple nn.2 Linears. 2 drops. loss: {}\\\n",
    "                               Separate shift for each feature. seq_len = 1.180-220 range for shift. No shift in rates\\\n",
    "                               No normalisation. Only first 2 fold and test set(last fold).\\\n",
    "                               Dropped data before 2020-02-15 00:00:00'.format(loss),\n",
    "                               upload_source_files = ['cv.py', \n",
    "                                                      'load_data.py', \n",
    "                                                      'model_selection.py',\n",
    "                                                      'NN.py',\n",
    "                                                      'pl_framework.py',\n",
    "                                                      'preprocessing.py'])\n",
    "        my_training.set_up_studying(random_state = random_state)\n",
    "\n",
    "        model = 'torch'\n",
    "\n",
    "        def params_func(trial, X):\n",
    "            return(\n",
    "                {\n",
    "                    'target': target,\n",
    "                    'n_h_1': trial.suggest_int('n_h_1', 10, 1000),\n",
    "                    'batch_size': trial.suggest_int('batch_size', 10, 800),\n",
    "                    'p_1': trial.suggest_uniform('p_1', 0, 1),\n",
    "                    'p_2': trial.suggest_uniform('p_2', 0, 1),\n",
    "                    'lr': trial.suggest_loguniform('lr', 0.0001, 0.2),\n",
    "                    'weight_decay': trial.suggest_uniform('weight_decay', 0.0001, 1),\n",
    "                    'optimizer': 'AdamW',\n",
    "                    'loss': loss,\n",
    "                    'activation1': trial.suggest_categorical('activation1', ['Tanh','Hardtanh','Hardshrink', 'ELU' , \n",
    "                                                                             'SELU', 'ReLU', 'Tanhshrink', 'CELU']),\n",
    "                    'n_back_A_CH4': trial.suggest_int('n_back_A_CH4', 180, 220),\n",
    "                    'n_back_A_C2H6': trial.suggest_int('n_back_A_C2H6', 180, 220),\n",
    "                    'n_back_A_C3H8': trial.suggest_int('n_back_A_C3H8', 180, 220),\n",
    "                    'n_back_A_iC4H10': trial.suggest_int('n_back_A_iC4H10', 180, 220),\n",
    "                    'n_back_A_iC5H12': trial.suggest_int('n_back_A_iC5H12', 180, 220),\n",
    "                    'n_back_A_nC4H10': trial.suggest_int('n_back_A_nC4H10', 180, 220),\n",
    "                    'n_back_A_nC5H12': trial.suggest_int('n_back_A_nC5H12', 180, 220),\n",
    "                    'n_back_A_C6H14': trial.suggest_int('n_back_A_C6H14', 180, 220)\n",
    "\n",
    "        }\n",
    "            )\n",
    "\n",
    "\n",
    "        n_trials = 30\n",
    "        my_training.train(X = train_features, \n",
    "                          y = train_targets, \n",
    "                          cv = cv, \n",
    "                          model=model, \n",
    "                          params_func = params_func, \n",
    "                          n_trials = n_trials)\n",
    "        neptune.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "for boosting in ['gbdt', 'dart', 'goss']:\n",
    "    for objective in ['huber', 'fair', 'l2', 'l1', 'mape']:\n",
    "        for target in ['C2H6', 'C3H8', 'iC4H10', 'nC4H10']:\n",
    "            my_training = training(name = target,\n",
    "                                   description = 'Ffill. 1 train for each fold. LGBM. boosting = {}, objective = {}\\\n",
    "                                   Separate shift for each feature. seq_len = 1.180-220 range for shift. No shift in rates. features+features 1, 2, 3 ... n days ago\\\n",
    "                                   No normalisation. Only first 2 fold and test set(last fold).feature fraction = 1\\\n",
    "                                   Dropped data before 2020-02-15 00:00:00'.format(boosting, objective),\n",
    "                                   upload_source_files = ['cv.py', \n",
    "                                                          'load_data.py', \n",
    "                                                          'model_selection.py',\n",
    "                                                          'NN.py',\n",
    "                                                          'pl_framework.py',\n",
    "                                                          'preprocessing.py'])\n",
    "            my_training.set_up_studying(random_state = random_state)\n",
    "\n",
    "            model = 'lgbm'\n",
    "\n",
    "            def params_func(trial, X):\n",
    "                return(\n",
    "                    {\n",
    "                        'target': target,\n",
    "                        'objective': objective,\n",
    "                        'boosting': boosting,\n",
    "                        'n_jobs': -1,\n",
    "                        'n_estimators': 1,\n",
    "                        'random_state': random_state,\n",
    "                        'bagging_fraction': 1,\n",
    "                        'feature_fraction': 1,\n",
    "                        'n_today': trial.suggest_int('n_today', 0, 100),\n",
    "                        'min_child_samples': trial.suggest_int('min_child_samples', 2, 256),\n",
    "                        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "                        'learning_rate': trial.suggest_uniform('learning_rate', 0.01, 1.5),\n",
    "                        'n_back_A_CH4': trial.suggest_int('n_back_A_CH4', 180, 220),\n",
    "                        'n_back_A_C2H6': trial.suggest_int('n_back_A_C2H6', 180, 220),\n",
    "                        'n_back_A_C3H8': trial.suggest_int('n_back_A_C3H8', 180, 220),\n",
    "                        'n_back_A_iC4H10': trial.suggest_int('n_back_A_iC4H10', 180, 220),\n",
    "                        'n_back_A_iC5H12': trial.suggest_int('n_back_A_iC5H12', 180, 220),\n",
    "                        'n_back_A_nC4H10': trial.suggest_int('n_back_A_nC4H10', 180, 220),\n",
    "                        'n_back_A_nC5H12': trial.suggest_int('n_back_A_nC5H12', 180, 220),\n",
    "                        'n_back_A_C6H14': trial.suggest_int('n_back_A_C6H14', 180, 220)\n",
    "\n",
    "\n",
    "            }\n",
    "                )\n",
    "\n",
    "\n",
    "            n_trials = 15000\n",
    "            my_training.train(X = train_features, \n",
    "                              y = train_targets, \n",
    "                              cv = cv, \n",
    "                              model = model, \n",
    "                              params_func = params_func, \n",
    "                              n_trials = n_trials)\n",
    "            neptune.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "for target in ['C2H6', 'C3H8', 'iC4H10', 'nC4H10']:\n",
    "    for random_state in [223, 245, 267, 12345, 998, 1456, 938, 223, 16]:\n",
    "        my_training = training(name = 'B_' + target, sklearn_class = SGDRegressor,\n",
    "                               description = 'Ffill. 1 train for each fold. Linear regression. WEIGHTED\\\n",
    "                               Separate shift for each feature. seq_len = 1.180-220 range for shift. No shift in rates. Features = A_target, constant\\\n",
    "                               No normalisation. Only first 2 fold and test set(last fold)\\\n",
    "                               Dropped data before 2020-02-15 00:00:00',\n",
    "                               upload_source_files = ['cv.py', \n",
    "                                                      'load_data.py', \n",
    "                                                      'model_selection.py',\n",
    "                                                      'NN.py',\n",
    "                                                      'pl_framework.py',\n",
    "                                                      'preprocessing.py'])\n",
    "        my_training.set_up_studying(random_state = random_state)\n",
    "\n",
    "        model = 'sklearn'\n",
    "\n",
    "        def params_func(trial, X):\n",
    "            return(\n",
    "                {\n",
    "                    'target': target,\n",
    "                    'random_state': random_state,\n",
    "                    'loss': 'epsilon_insensitive',\n",
    "                    'epsilon': 0,\n",
    "                    'tol': 1e-5,\n",
    "                    'n_back_A_{}'.format(target): trial.suggest_int('n_back_A_{}'.format(target), 180, 220)\n",
    "\n",
    "\n",
    "        }\n",
    "            )\n",
    "\n",
    "\n",
    "        n_trials = 250\n",
    "        my_training.train(X = train_features, \n",
    "                          y = train_targets, \n",
    "                          cv = cv, \n",
    "                          model = model, \n",
    "                          params_func = params_func, \n",
    "                          n_trials = n_trials)\n",
    "        neptune.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "neptune": {
   "notebookId": "3334104b-e4da-40ca-a353-d78790164c0b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
