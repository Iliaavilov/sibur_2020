{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import neptune\n",
    "\n",
    "from NN import simple_torchpl\n",
    "from load_data import load\n",
    "from pl_framework import nn_training\n",
    "from cv import get_indices\n",
    "import preprocessing\n",
    "\n",
    "import torch\n",
    "import json\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There is a new version of neptune-client 0.4.125 (installed: 0.4.124).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Project(iliaavilov/SIBUR)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neptune.init('iliaavilov/SIBUR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/'\n",
    "random_state = 54321\n",
    "pd.options.display.max_rows = 999\n",
    "features = ['A_rate', 'A_CH4', 'A_C2H6', 'A_C3H8', 'A_iC4H10', 'A_nC4H10',\n",
    "            'A_iC5H12', 'A_nC5H12', 'A_C6H14', 'B_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_targets, test_features = load(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = get_indices(train_targets, [(pd.to_datetime('2020-03-01 00:00:00'), pd.to_datetime('2020-03-15 00:00:00')),\n",
    "                                 (pd.to_datetime('2020-03-15 00:00:00'), pd.to_datetime('2020-03-31 00:00:00')),\n",
    "                                 (pd.to_datetime('2020-04-15 00:00:00'), pd.to_datetime('2020-04-30 00:00:00'))\n",
    "                                ]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = test_features['timestamp'].values\n",
    "train_targets = train_targets.drop('timestamp', axis = 'columns')\n",
    "test_features = test_features.drop('timestamp', axis = 'columns')\n",
    "train_features = train_features.drop('timestamp', axis = 'columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предсказания для теста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp_index = 'SIB-245'\n",
    "n_trial = 14\n",
    "\n",
    "\n",
    "exp = neptune.project.get_experiments(exp_index)[0]\n",
    "\n",
    "channel_names = ['run_parameters']\n",
    "channels_data = {}\n",
    "channels_by_name = exp.get_channels()\n",
    "for channel_name in channel_names:\n",
    "    channel_id = channels_by_name[channel_name].id\n",
    "\n",
    "    channels_data[channel_name] = pd.read_csv(\n",
    "        exp._backend.get_channel_points_csv(exp, channel_id),\n",
    "        header=None,\n",
    "        dtype=str\n",
    "    )\n",
    "    \n",
    "values = exp._backend.get_channel_points_csv(exp, channel_id).getvalue()\n",
    "data = pd.DataFrame(values.split('\\n'))\n",
    "data = data.iloc[:-1]\n",
    "data[0] = data[0].apply(lambda x: json.loads('{' + x.split(',{')[1].replace(\"'\", '\"')))\n",
    "data.columns = ['params']\n",
    "#iterations = exp.get_numeric_channels_values('iterations').drop('x', axis = 'columns')\n",
    "#data = pd.concat([data, iterations], axis = 'columns')\n",
    "\n",
    "data_trial = data.iloc[n_trial, ]\n",
    "params_trial = data_trial['params']\n",
    "#params_trial['mean_best_iter'] = data_trial['iterations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_trial['n_in'] = 20\n",
    "params_trial['n_out'] = 1\n",
    "params_trial['optimizer'] = 'AdamW'\n",
    "params_trial['loss'] = torch.nn.L1Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current params: {'seq_len': 55, 'n_back': 44, 'n_rolling': 5, 'n_h_1': 368, 'batch_size': 730, 'p_1': 0.30358383224208985, 'activation1': 'Hardshrink', 'lr': 0.0004029769361640069, 'weight_decay': 0.998154546960057, 'n_in': 20, 'n_out': 1, 'optimizer': 'AdamW', 'loss': <class 'torch.nn.modules.loss.L1Loss'>}\n",
      "Initial shape of X: (7631, 10)\n",
      "cv before trans: 719\n",
      "Initial shape of X after rolling: (7587, 20)\n",
      "Initial shape of y: (3647, 4)\n",
      "cv after trans: 621\n",
      "shape of X after trans: (7533, 55, 20)\n",
      "shape of y after trans: (3549, 4)\n"
     ]
    }
   ],
   "source": [
    "all_features = train_features.append(test_features, ignore_index = True)\n",
    "\n",
    "X, y_train, cv, params = preprocessing.preprocessing(all_features.copy(), \n",
    "                                                     train_targets.copy(), \n",
    "                                                     copy.deepcopy(cv), \n",
    "                                                     copy.deepcopy(params_trial), \n",
    "                                                     pop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = params['seq_len']\n",
    "n_back = params['n_back']\n",
    "n_rolling = params['n_rolling']\n",
    "batch_size = params['batch_size']\n",
    "\n",
    "\n",
    "params.pop('batch_size')\n",
    "params.pop('seq_len')\n",
    "params.pop('n_back')\n",
    "params.pop('n_rolling')\n",
    "\n",
    "X_train = X[:(train_features.shape[0] - ((seq_len - 1) + max(n_rolling - 1, n_back)))]\n",
    "X_test = X[(train_features.shape[0] - ((seq_len - 1) + max(n_rolling - 1, n_back))):]\n",
    "\n",
    "X_train = X_train\n",
    "X_test = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3549, 4)\n",
      "(3549, 55, 20)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3984, 10)\n",
      "(3984, 55, 20)\n"
     ]
    }
   ],
   "source": [
    "print(test_features.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fold = cv[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type       | Params\n",
      "--------------------------------------------\n",
      "0 | activ1       | Hardshrink | 0     \n",
      "1 | lstm         | LSTM       | 574 K \n",
      "2 | dropout1     | Dropout    | 0     \n",
      "3 | linear_final | Linear     | 369   \n",
      "4 | loss         | L1Loss     | 0     \n",
      "5 | loss_sec     | MAPE       | 0     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.0070767402648926\n",
      "val_loss: 0.9515213966369629\n",
      "train_loss: 0.9487589597702026\n",
      "val_loss: 0.9034141302108765\n",
      "train_loss: 0.9036100506782532\n",
      "val_loss: 0.8501515984535217\n",
      "train_loss: 0.8418893814086914\n",
      "val_loss: 0.80669105052948\n",
      "train_loss: 0.8058381676673889\n",
      "val_loss: 0.7689621448516846\n",
      "train_loss: 0.7627676725387573\n",
      "val_loss: 0.7518856525421143\n",
      "train_loss: 0.743324339389801\n",
      "val_loss: 0.7250412702560425\n",
      "train_loss: 0.7198963761329651\n",
      "val_loss: 0.7023882865905762\n",
      "train_loss: 0.6954436898231506\n",
      "val_loss: 0.6797585487365723\n",
      "train_loss: 0.6729488372802734\n",
      "val_loss: 0.6577469110488892\n",
      "train_loss: 0.6493890285491943\n",
      "val_loss: 0.6388629674911499\n",
      "train_loss: 0.6310581564903259\n",
      "val_loss: 0.6104918122291565\n",
      "train_loss: 0.6045486330986023\n",
      "val_loss: 0.5691959857940674\n",
      "train_loss: 0.559861421585083\n",
      "val_loss: 0.5351738929748535\n",
      "train_loss: 0.5267188549041748\n",
      "val_loss: 0.5019721984863281\n",
      "train_loss: 0.4945843815803528\n",
      "val_loss: 0.4634927213191986\n",
      "train_loss: 0.4585554599761963\n",
      "val_loss: 0.43680539727211\n",
      "train_loss: 0.42791953682899475\n",
      "val_loss: 0.4157130718231201\n",
      "train_loss: 0.4034128487110138\n",
      "val_loss: 0.3969614803791046\n",
      "train_loss: 0.380809485912323\n",
      "val_loss: 0.3740746080875397\n",
      "train_loss: 0.3620467782020569\n",
      "val_loss: 0.3459053039550781\n",
      "train_loss: 0.3317737281322479\n",
      "val_loss: 0.3190153241157532\n",
      "train_loss: 0.30008238554000854\n",
      "val_loss: 0.29090622067451477\n",
      "train_loss: 0.27820271253585815\n",
      "val_loss: 0.2641173303127289\n",
      "train_loss: 0.2500772476196289\n",
      "val_loss: 0.24627035856246948\n",
      "train_loss: 0.2390599399805069\n",
      "val_loss: 0.2265375703573227\n",
      "train_loss: 0.21180441975593567\n",
      "val_loss: 0.19502244889736176\n",
      "train_loss: 0.1889626830816269\n",
      "val_loss: 0.1678791046142578\n",
      "train_loss: 0.15865008533000946\n",
      "val_loss: 0.14690762758255005\n",
      "train_loss: 0.13695283234119415\n",
      "val_loss: 0.11336895078420639\n",
      "train_loss: 0.10555430501699448\n",
      "val_loss: 0.09750309586524963\n",
      "train_loss: 0.09625952690839767\n",
      "val_loss: 0.07681413739919662\n",
      "train_loss: 0.08080986887216568\n",
      "val_loss: 0.06149108707904816\n",
      "train_loss: 0.07628138363361359\n",
      "val_loss: 0.05537388473749161\n",
      "train_loss: 0.07538385689258575\n",
      "val_loss: 0.05427561327815056\n",
      "train_loss: 0.07690317928791046\n",
      "val_loss: 0.053806520998477936\n",
      "train_loss: 0.07756667584180832\n",
      "val_loss: 0.05455966293811798\n",
      "train_loss: 0.07382813096046448\n",
      "val_loss: 0.05484690144658089\n",
      "train_loss: 0.07529741525650024\n",
      "val_loss: 0.05420984700322151\n",
      "train_loss: 0.07714910060167313\n",
      "val_loss: 0.053478922694921494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type       | Params\n",
      "--------------------------------------------\n",
      "0 | activ1       | Hardshrink | 0     \n",
      "1 | lstm         | LSTM       | 574 K \n",
      "2 | dropout1     | Dropout    | 0     \n",
      "3 | linear_final | Linear     | 369   \n",
      "4 | loss         | L1Loss     | 0     \n",
      "5 | loss_sec     | MAPE       | 0     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.0008121728897095\n",
      "val_loss: 0.9944166541099548\n",
      "train_loss: 0.9943521618843079\n",
      "val_loss: 0.9888656139373779\n",
      "train_loss: 0.9894086718559265\n",
      "val_loss: 0.9827278852462769\n",
      "train_loss: 0.9825699925422668\n",
      "val_loss: 0.9777119755744934\n",
      "train_loss: 0.9785787463188171\n",
      "val_loss: 0.9733657836914062\n",
      "train_loss: 0.9738399982452393\n",
      "val_loss: 0.9713890552520752\n",
      "train_loss: 0.9717029929161072\n",
      "val_loss: 0.9682936668395996\n",
      "train_loss: 0.9691274166107178\n",
      "val_loss: 0.9656826257705688\n",
      "train_loss: 0.9664115905761719\n",
      "val_loss: 0.9630657434463501\n",
      "train_loss: 0.9639670252799988\n",
      "val_loss: 0.9605265855789185\n",
      "train_loss: 0.961336076259613\n",
      "val_loss: 0.9583483338356018\n",
      "train_loss: 0.959333598613739\n",
      "val_loss: 0.9550822377204895\n",
      "train_loss: 0.9564092755317688\n",
      "val_loss: 0.9503219127655029\n",
      "train_loss: 0.9514679312705994\n",
      "val_loss: 0.9463974833488464\n",
      "train_loss: 0.947783887386322\n",
      "val_loss: 0.942564845085144\n",
      "train_loss: 0.9442609548568726\n",
      "val_loss: 0.9381332397460938\n",
      "train_loss: 0.9401835799217224\n",
      "val_loss: 0.9350483417510986\n",
      "train_loss: 0.9366891384124756\n",
      "val_loss: 0.9326218962669373\n",
      "train_loss: 0.9340001344680786\n",
      "val_loss: 0.9304556846618652\n",
      "train_loss: 0.9314184784889221\n",
      "val_loss: 0.9278101325035095\n",
      "train_loss: 0.9292533993721008\n",
      "val_loss: 0.9245638251304626\n",
      "train_loss: 0.9258618354797363\n",
      "val_loss: 0.9214484691619873\n",
      "train_loss: 0.9222946763038635\n",
      "val_loss: 0.9181938171386719\n",
      "train_loss: 0.9198988676071167\n",
      "val_loss: 0.9151103496551514\n",
      "train_loss: 0.9166856408119202\n",
      "val_loss: 0.9130385518074036\n",
      "train_loss: 0.9154187440872192\n",
      "val_loss: 0.9107686281204224\n",
      "train_loss: 0.9122732877731323\n",
      "val_loss: 0.9070696234703064\n",
      "train_loss: 0.9096319675445557\n",
      "val_loss: 0.9039263129234314\n",
      "train_loss: 0.9060523509979248\n",
      "val_loss: 0.9013535380363464\n",
      "train_loss: 0.9031888842582703\n",
      "val_loss: 0.8970255255699158\n",
      "train_loss: 0.8991056680679321\n",
      "val_loss: 0.894568145275116\n",
      "train_loss: 0.8969296216964722\n",
      "val_loss: 0.8916029334068298\n",
      "train_loss: 0.8940765857696533\n",
      "val_loss: 0.8882400989532471\n",
      "train_loss: 0.8912621140480042\n",
      "val_loss: 0.8854333758354187\n",
      "train_loss: 0.8883158564567566\n",
      "val_loss: 0.8831669688224792\n",
      "train_loss: 0.8850141167640686\n",
      "val_loss: 0.8814896941184998\n",
      "train_loss: 0.8838008642196655\n",
      "val_loss: 0.8775565028190613\n",
      "train_loss: 0.8803369998931885\n",
      "val_loss: 0.874115526676178\n",
      "train_loss: 0.8771024942398071\n",
      "val_loss: 0.8715885877609253\n",
      "train_loss: 0.8740127086639404\n",
      "val_loss: 0.8693128228187561\n",
      "train_loss: 0.8722898960113525\n",
      "val_loss: 0.8656371831893921\n",
      "train_loss: 0.8682792782783508\n",
      "val_loss: 0.8632696866989136\n",
      "train_loss: 0.8667792081832886\n",
      "val_loss: 0.8610156774520874\n",
      "train_loss: 0.8642218112945557\n",
      "val_loss: 0.8591615557670593\n",
      "train_loss: 0.8618106842041016\n",
      "val_loss: 0.8570013642311096\n",
      "train_loss: 0.8592463731765747\n",
      "val_loss: 0.8544469475746155\n",
      "train_loss: 0.8568933010101318\n",
      "val_loss: 0.8520233631134033\n",
      "train_loss: 0.8551039099693298\n",
      "val_loss: 0.8482239842414856\n",
      "train_loss: 0.8520146012306213\n",
      "val_loss: 0.8452805876731873\n",
      "train_loss: 0.8490073084831238\n",
      "val_loss: 0.8424703478813171\n",
      "train_loss: 0.8466713428497314\n",
      "val_loss: 0.8395739793777466\n",
      "train_loss: 0.8429177403450012\n",
      "val_loss: 0.8372927904129028\n",
      "train_loss: 0.8409515023231506\n",
      "val_loss: 0.8352335095405579\n",
      "train_loss: 0.8389430642127991\n",
      "val_loss: 0.8326848149299622\n",
      "train_loss: 0.8368957042694092\n",
      "val_loss: 0.8301060795783997\n",
      "train_loss: 0.8341676592826843\n",
      "val_loss: 0.8271718621253967\n",
      "train_loss: 0.83170485496521\n",
      "val_loss: 0.8248266577720642\n",
      "train_loss: 0.8297034502029419\n",
      "val_loss: 0.8220396637916565\n",
      "train_loss: 0.8262041211128235\n",
      "val_loss: 0.8195683360099792\n",
      "train_loss: 0.823823869228363\n",
      "val_loss: 0.8173271417617798\n",
      "train_loss: 0.8219403028488159\n",
      "val_loss: 0.8152565956115723\n",
      "train_loss: 0.8194488286972046\n",
      "val_loss: 0.812473475933075\n",
      "train_loss: 0.8169821500778198\n",
      "val_loss: 0.8094631433486938\n",
      "train_loss: 0.8142801523208618\n",
      "val_loss: 0.8062544465065002\n",
      "train_loss: 0.8117074370384216\n",
      "val_loss: 0.8038843274116516\n",
      "train_loss: 0.8090715408325195\n",
      "val_loss: 0.8012635111808777\n",
      "train_loss: 0.8072304129600525\n",
      "val_loss: 0.7987102270126343\n",
      "train_loss: 0.8032206296920776\n",
      "val_loss: 0.7960349321365356\n",
      "train_loss: 0.8013438582420349\n",
      "val_loss: 0.7938107252120972\n",
      "train_loss: 0.7987598180770874\n",
      "val_loss: 0.7914692759513855\n",
      "train_loss: 0.7966015934944153\n",
      "val_loss: 0.7881077527999878\n",
      "train_loss: 0.7934610843658447\n",
      "val_loss: 0.7855151891708374\n",
      "train_loss: 0.7900033593177795\n",
      "val_loss: 0.7830774188041687\n",
      "train_loss: 0.7876194715499878\n",
      "val_loss: 0.7805591821670532\n",
      "train_loss: 0.7863681316375732\n",
      "val_loss: 0.7777350544929504\n",
      "train_loss: 0.783048689365387\n",
      "val_loss: 0.7752162218093872\n",
      "train_loss: 0.7807058691978455\n",
      "val_loss: 0.7729670405387878\n",
      "train_loss: 0.7790572047233582\n",
      "val_loss: 0.7701801061630249\n",
      "train_loss: 0.776431143283844\n",
      "val_loss: 0.7677595019340515\n",
      "train_loss: 0.7731417417526245\n",
      "val_loss: 0.7654183506965637\n",
      "train_loss: 0.7722466588020325\n",
      "val_loss: 0.7631052732467651\n",
      "train_loss: 0.7691438794136047\n",
      "val_loss: 0.7607893943786621\n",
      "train_loss: 0.7669645547866821\n",
      "val_loss: 0.7583866119384766\n",
      "train_loss: 0.7644784450531006\n",
      "val_loss: 0.7560609579086304\n",
      "train_loss: 0.7620219588279724\n",
      "val_loss: 0.7537604570388794\n",
      "train_loss: 0.759669303894043\n",
      "val_loss: 0.7514814734458923\n",
      "train_loss: 0.7579604387283325\n",
      "val_loss: 0.7491474151611328\n",
      "train_loss: 0.7558133006095886\n",
      "val_loss: 0.7468202710151672\n",
      "train_loss: 0.7528244853019714\n",
      "val_loss: 0.7443458437919617\n",
      "train_loss: 0.7506195902824402\n",
      "val_loss: 0.7416210174560547\n",
      "train_loss: 0.7478715181350708\n",
      "val_loss: 0.7391446232795715\n",
      "train_loss: 0.7458412647247314\n",
      "val_loss: 0.7362607717514038\n",
      "train_loss: 0.7426374554634094\n",
      "val_loss: 0.733383297920227\n",
      "train_loss: 0.7405431866645813\n",
      "val_loss: 0.7308869361877441\n",
      "train_loss: 0.7372046113014221\n",
      "val_loss: 0.7285037636756897\n",
      "train_loss: 0.7349463105201721\n",
      "val_loss: 0.726043164730072\n",
      "train_loss: 0.7318804264068604\n",
      "val_loss: 0.723829984664917\n",
      "train_loss: 0.7306250929832458\n",
      "val_loss: 0.7212685942649841\n",
      "train_loss: 0.7276015877723694\n",
      "val_loss: 0.7187933921813965\n",
      "train_loss: 0.7257652282714844\n",
      "val_loss: 0.7163277864456177\n",
      "train_loss: 0.723699152469635\n",
      "val_loss: 0.7137553691864014\n",
      "train_loss: 0.7211600542068481\n",
      "val_loss: 0.7113047242164612\n",
      "train_loss: 0.7191376090049744\n",
      "val_loss: 0.7089138627052307\n",
      "train_loss: 0.7162780165672302\n",
      "val_loss: 0.7065585851669312\n",
      "train_loss: 0.7137889266014099\n",
      "val_loss: 0.7042303681373596\n",
      "train_loss: 0.7113239765167236\n",
      "val_loss: 0.7019094824790955\n",
      "train_loss: 0.7094129920005798\n",
      "val_loss: 0.6996100544929504\n",
      "train_loss: 0.7073156833648682\n",
      "val_loss: 0.6972904205322266\n",
      "train_loss: 0.7046347856521606\n",
      "val_loss: 0.6949736475944519\n",
      "train_loss: 0.7032262682914734\n",
      "val_loss: 0.6921648979187012\n",
      "train_loss: 0.7001680135726929\n",
      "val_loss: 0.6890996694564819\n",
      "train_loss: 0.696997880935669\n",
      "val_loss: 0.6865695714950562\n",
      "train_loss: 0.6951064467430115\n",
      "val_loss: 0.6841104626655579\n",
      "train_loss: 0.6922485828399658\n",
      "val_loss: 0.6816508173942566\n",
      "train_loss: 0.6898421049118042\n",
      "val_loss: 0.6792422533035278\n",
      "train_loss: 0.6877468228340149\n",
      "val_loss: 0.6769669651985168\n",
      "train_loss: 0.6846709847450256\n",
      "val_loss: 0.67491215467453\n",
      "train_loss: 0.6836270093917847\n",
      "val_loss: 0.6721597909927368\n",
      "train_loss: 0.6798001527786255\n",
      "val_loss: 0.6696785688400269\n",
      "train_loss: 0.6783090829849243\n",
      "val_loss: 0.6672890186309814\n",
      "train_loss: 0.6763336062431335\n",
      "val_loss: 0.6648764610290527\n",
      "train_loss: 0.6737831830978394\n",
      "val_loss: 0.6624913215637207\n",
      "train_loss: 0.6715673804283142\n",
      "val_loss: 0.6601614952087402\n",
      "train_loss: 0.6690515279769897\n",
      "val_loss: 0.6578086018562317\n",
      "train_loss: 0.6656179428100586\n",
      "val_loss: 0.6554954051971436\n",
      "train_loss: 0.6639386415481567\n",
      "val_loss: 0.6531972885131836\n",
      "train_loss: 0.6619381904602051\n",
      "val_loss: 0.6508828997612\n",
      "train_loss: 0.6593446731567383\n",
      "val_loss: 0.648566722869873\n",
      "train_loss: 0.6573907732963562\n",
      "val_loss: 0.6463286280632019\n",
      "train_loss: 0.6541092991828918\n",
      "val_loss: 0.6439968943595886\n",
      "train_loss: 0.6540918350219727\n",
      "val_loss: 0.6417069435119629\n",
      "train_loss: 0.6512691378593445\n",
      "val_loss: 0.6394267678260803\n",
      "train_loss: 0.649198055267334\n",
      "val_loss: 0.6371394395828247\n",
      "train_loss: 0.6456508636474609\n",
      "val_loss: 0.6348412036895752\n",
      "train_loss: 0.6442805528640747\n",
      "val_loss: 0.6325427293777466\n",
      "train_loss: 0.6430746912956238\n",
      "val_loss: 0.6302610039710999\n",
      "train_loss: 0.6394058465957642\n",
      "val_loss: 0.6279658675193787\n",
      "train_loss: 0.637580931186676\n",
      "val_loss: 0.6256594061851501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.6349326372146606\n",
      "val_loss: 0.623296320438385\n",
      "train_loss: 0.6336749792098999\n",
      "val_loss: 0.6207473874092102\n",
      "train_loss: 0.6294881701469421\n",
      "val_loss: 0.6183459162712097\n",
      "train_loss: 0.6272920966148376\n",
      "val_loss: 0.6162188649177551\n",
      "train_loss: 0.6257582902908325\n",
      "val_loss: 0.6135138869285583\n",
      "train_loss: 0.6240156888961792\n",
      "val_loss: 0.6111787557601929\n",
      "train_loss: 0.620364248752594\n",
      "val_loss: 0.6088472604751587\n",
      "train_loss: 0.6184828281402588\n",
      "val_loss: 0.6065317392349243\n",
      "train_loss: 0.6168798804283142\n",
      "val_loss: 0.6042200922966003\n",
      "train_loss: 0.615283191204071\n",
      "val_loss: 0.6019061207771301\n",
      "train_loss: 0.6139030456542969\n",
      "val_loss: 0.5995810627937317\n",
      "train_loss: 0.6077295541763306\n",
      "val_loss: 0.5972509384155273\n",
      "train_loss: 0.6072489619255066\n",
      "val_loss: 0.5948874950408936\n",
      "train_loss: 0.6051309108734131\n",
      "val_loss: 0.5925148129463196\n",
      "train_loss: 0.6038682460784912\n",
      "val_loss: 0.5901455283164978\n",
      "train_loss: 0.6006131768226624\n",
      "val_loss: 0.5877969861030579\n",
      "train_loss: 0.5989593863487244\n",
      "val_loss: 0.5854666829109192\n",
      "train_loss: 0.5969791412353516\n",
      "val_loss: 0.5831203460693359\n",
      "train_loss: 0.5929489731788635\n",
      "val_loss: 0.5807806849479675\n",
      "train_loss: 0.592488169670105\n",
      "val_loss: 0.57844477891922\n",
      "train_loss: 0.5880755186080933\n",
      "val_loss: 0.5761106610298157\n",
      "train_loss: 0.5871484279632568\n",
      "val_loss: 0.5737804770469666\n",
      "train_loss: 0.5851284861564636\n",
      "val_loss: 0.5714563727378845\n",
      "train_loss: 0.5829348564147949\n",
      "val_loss: 0.5691483616828918\n",
      "train_loss: 0.5812950134277344\n",
      "val_loss: 0.5668349266052246\n",
      "train_loss: 0.5768599510192871\n",
      "val_loss: 0.5645318031311035\n",
      "train_loss: 0.5750296115875244\n",
      "val_loss: 0.5622314810752869\n",
      "train_loss: 0.5720393061637878\n",
      "val_loss: 0.5599358677864075\n",
      "train_loss: 0.5716285705566406\n",
      "val_loss: 0.5576397180557251\n",
      "train_loss: 0.568924605846405\n",
      "val_loss: 0.5553480982780457\n",
      "train_loss: 0.5670252442359924\n",
      "val_loss: 0.5530553460121155\n",
      "train_loss: 0.5645615458488464\n",
      "val_loss: 0.5507550239562988\n",
      "train_loss: 0.5608051419258118\n",
      "val_loss: 0.5484527349472046\n",
      "train_loss: 0.5597322583198547\n",
      "val_loss: 0.5461646318435669\n",
      "train_loss: 0.5586304664611816\n",
      "val_loss: 0.5438748598098755\n",
      "train_loss: 0.5543703436851501\n",
      "val_loss: 0.5415920615196228\n",
      "train_loss: 0.5528620481491089\n",
      "val_loss: 0.5393123626708984\n",
      "train_loss: 0.5490727424621582\n",
      "val_loss: 0.5370498895645142\n",
      "train_loss: 0.5480695366859436\n",
      "val_loss: 0.5347808003425598\n",
      "train_loss: 0.5462818741798401\n",
      "val_loss: 0.532503604888916\n",
      "train_loss: 0.544068455696106\n",
      "val_loss: 0.5302380323410034\n",
      "train_loss: 0.5437314510345459\n",
      "val_loss: 0.5279658436775208\n",
      "train_loss: 0.5402392148971558\n",
      "val_loss: 0.5256863832473755\n",
      "train_loss: 0.5373799800872803\n",
      "val_loss: 0.5234063267707825\n",
      "train_loss: 0.5365822911262512\n",
      "val_loss: 0.5211313962936401\n",
      "train_loss: 0.5342699289321899\n",
      "val_loss: 0.5188518762588501\n",
      "train_loss: 0.5304793119430542\n",
      "val_loss: 0.516582727432251\n",
      "train_loss: 0.5285979509353638\n",
      "val_loss: 0.5143164396286011\n",
      "train_loss: 0.5257959365844727\n",
      "val_loss: 0.512032151222229\n",
      "train_loss: 0.525592029094696\n",
      "val_loss: 0.5097222924232483\n",
      "train_loss: 0.5214594006538391\n",
      "val_loss: 0.5074217319488525\n",
      "train_loss: 0.5198405385017395\n",
      "val_loss: 0.505102813243866\n",
      "train_loss: 0.5150235891342163\n",
      "val_loss: 0.5027863383293152\n",
      "train_loss: 0.5143534541130066\n",
      "val_loss: 0.50047767162323\n",
      "train_loss: 0.5128846764564514\n",
      "val_loss: 0.4981763958930969\n",
      "train_loss: 0.5103474259376526\n",
      "val_loss: 0.49587520956993103\n",
      "train_loss: 0.5083349943161011\n",
      "val_loss: 0.4935564696788788\n",
      "train_loss: 0.5066983699798584\n",
      "val_loss: 0.49123483896255493\n",
      "train_loss: 0.5057412385940552\n",
      "val_loss: 0.4889119863510132\n",
      "train_loss: 0.5020540356636047\n",
      "val_loss: 0.4865780770778656\n",
      "train_loss: 0.49840059876441956\n",
      "val_loss: 0.48424142599105835\n",
      "train_loss: 0.4976385831832886\n",
      "val_loss: 0.4818924367427826\n",
      "train_loss: 0.4944377541542053\n",
      "val_loss: 0.47954049706459045\n",
      "train_loss: 0.4928410053253174\n",
      "val_loss: 0.47719064354896545\n",
      "train_loss: 0.48881179094314575\n",
      "val_loss: 0.4748491644859314\n",
      "train_loss: 0.488190233707428\n",
      "val_loss: 0.4724840521812439\n",
      "train_loss: 0.48599281907081604\n",
      "val_loss: 0.4701639413833618\n",
      "train_loss: 0.48205333948135376\n",
      "val_loss: 0.4678262174129486\n",
      "train_loss: 0.4805000126361847\n",
      "val_loss: 0.46541017293930054\n",
      "train_loss: 0.47908350825309753\n",
      "val_loss: 0.4630814492702484\n",
      "train_loss: 0.4765957295894623\n",
      "val_loss: 0.4607737362384796\n",
      "train_loss: 0.47579318284988403\n",
      "val_loss: 0.45850563049316406\n",
      "train_loss: 0.4715070128440857\n",
      "val_loss: 0.4561258852481842\n",
      "train_loss: 0.4706604778766632\n",
      "val_loss: 0.4538152813911438\n",
      "train_loss: 0.46776676177978516\n",
      "val_loss: 0.4515068829059601\n",
      "train_loss: 0.46618008613586426\n",
      "val_loss: 0.44919535517692566\n",
      "train_loss: 0.46412062644958496\n",
      "val_loss: 0.4468746781349182\n",
      "train_loss: 0.4595285952091217\n",
      "val_loss: 0.44453510642051697\n",
      "train_loss: 0.45866721868515015\n",
      "val_loss: 0.4422075152397156\n",
      "train_loss: 0.4565628170967102\n",
      "val_loss: 0.4398813247680664\n",
      "train_loss: 0.45402008295059204\n",
      "val_loss: 0.4375583231449127\n",
      "train_loss: 0.45012131333351135\n",
      "val_loss: 0.43523016571998596\n",
      "train_loss: 0.44833904504776\n",
      "val_loss: 0.4329012334346771\n",
      "train_loss: 0.44697901606559753\n",
      "val_loss: 0.43058109283447266\n",
      "train_loss: 0.44424402713775635\n",
      "val_loss: 0.4282599985599518\n",
      "train_loss: 0.44052138924598694\n",
      "val_loss: 0.4259328246116638\n",
      "train_loss: 0.44014519453048706\n",
      "val_loss: 0.4235905706882477\n",
      "train_loss: 0.4400392472743988\n",
      "val_loss: 0.4212415814399719\n",
      "train_loss: 0.4339427053928375\n",
      "val_loss: 0.41893213987350464\n",
      "train_loss: 0.4334382712841034\n",
      "val_loss: 0.41646039485931396\n",
      "train_loss: 0.432669460773468\n",
      "val_loss: 0.41407638788223267\n",
      "train_loss: 0.4274832606315613\n",
      "val_loss: 0.41169238090515137\n",
      "train_loss: 0.42740193009376526\n",
      "val_loss: 0.40930625796318054\n",
      "train_loss: 0.4242088198661804\n",
      "val_loss: 0.4069083034992218\n",
      "train_loss: 0.4216708242893219\n",
      "val_loss: 0.40449824929237366\n",
      "train_loss: 0.41868269443511963\n",
      "val_loss: 0.40208354592323303\n",
      "train_loss: 0.41950279474258423\n",
      "val_loss: 0.39966627955436707\n",
      "train_loss: 0.41702914237976074\n",
      "val_loss: 0.3972558379173279\n",
      "train_loss: 0.41215354204177856\n",
      "val_loss: 0.3947973847389221\n",
      "train_loss: 0.41037553548812866\n",
      "val_loss: 0.39213481545448303\n",
      "train_loss: 0.4084226191043854\n",
      "val_loss: 0.3894415497779846\n",
      "train_loss: 0.4050554633140564\n",
      "val_loss: 0.3869819641113281\n",
      "train_loss: 0.40380391478538513\n",
      "val_loss: 0.38450735807418823\n",
      "train_loss: 0.39954066276550293\n",
      "val_loss: 0.3820822238922119\n",
      "train_loss: 0.39791369438171387\n",
      "val_loss: 0.37966904044151306\n",
      "train_loss: 0.39473339915275574\n",
      "val_loss: 0.37727484107017517\n",
      "train_loss: 0.39353248476982117\n",
      "val_loss: 0.3748698830604553\n",
      "train_loss: 0.3927544355392456\n",
      "val_loss: 0.37239089608192444\n",
      "train_loss: 0.3890364170074463\n",
      "val_loss: 0.3699476718902588\n",
      "train_loss: 0.38475432991981506\n",
      "val_loss: 0.36749908328056335\n",
      "train_loss: 0.3830823004245758\n",
      "val_loss: 0.3650659918785095\n",
      "train_loss: 0.38185352087020874\n",
      "val_loss: 0.3625674843788147\n",
      "train_loss: 0.37799787521362305\n",
      "val_loss: 0.36010777950286865\n",
      "train_loss: 0.3753795921802521\n",
      "val_loss: 0.357658326625824\n",
      "train_loss: 0.3731336295604706\n",
      "val_loss: 0.35521477460861206\n",
      "train_loss: 0.37330177426338196\n",
      "val_loss: 0.35278409719467163\n",
      "train_loss: 0.37039709091186523\n",
      "val_loss: 0.35035115480422974\n",
      "train_loss: 0.3653201460838318\n",
      "val_loss: 0.3479365408420563\n",
      "train_loss: 0.3635671138763428\n",
      "val_loss: 0.34548431634902954\n",
      "train_loss: 0.36434707045555115\n",
      "val_loss: 0.3430436849594116\n",
      "train_loss: 0.3594484329223633\n",
      "val_loss: 0.34062284231185913\n",
      "train_loss: 0.35909804701805115\n",
      "val_loss: 0.33820900321006775\n",
      "train_loss: 0.3559754192829132\n",
      "val_loss: 0.3357986807823181\n",
      "train_loss: 0.35143420100212097\n",
      "val_loss: 0.33340904116630554\n",
      "train_loss: 0.3504752814769745\n",
      "val_loss: 0.33103278279304504\n",
      "train_loss: 0.3479011654853821\n",
      "val_loss: 0.3290482461452484\n",
      "train_loss: 0.3452686071395874\n",
      "val_loss: 0.32621997594833374\n",
      "train_loss: 0.34390515089035034\n",
      "val_loss: 0.323836088180542\n",
      "train_loss: 0.34160763025283813\n",
      "val_loss: 0.3214573264122009\n",
      "train_loss: 0.33768337965011597\n",
      "val_loss: 0.3190819323062897\n",
      "train_loss: 0.33798354864120483\n",
      "val_loss: 0.3167082369327545\n",
      "train_loss: 0.333730548620224\n",
      "val_loss: 0.3143390417098999\n",
      "train_loss: 0.3324241042137146\n",
      "val_loss: 0.3119751214981079\n",
      "train_loss: 0.3285103142261505\n",
      "val_loss: 0.30961233377456665\n",
      "train_loss: 0.32669514417648315\n",
      "val_loss: 0.30725523829460144\n",
      "train_loss: 0.3262280821800232\n",
      "val_loss: 0.30490434169769287\n",
      "train_loss: 0.32305219769477844\n",
      "val_loss: 0.3025457561016083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.31980428099632263\n",
      "val_loss: 0.30018410086631775\n",
      "train_loss: 0.3197762966156006\n",
      "val_loss: 0.29781991243362427\n",
      "train_loss: 0.31665486097335815\n",
      "val_loss: 0.29546087980270386\n",
      "train_loss: 0.3132074475288391\n",
      "val_loss: 0.29309946298599243\n",
      "train_loss: 0.3097435534000397\n",
      "val_loss: 0.2907469570636749\n",
      "train_loss: 0.3081795573234558\n",
      "val_loss: 0.2883918285369873\n",
      "train_loss: 0.3065032362937927\n",
      "val_loss: 0.2860323190689087\n",
      "train_loss: 0.304902046918869\n",
      "val_loss: 0.28366029262542725\n",
      "train_loss: 0.30047914385795593\n",
      "val_loss: 0.281297504901886\n",
      "train_loss: 0.3003719449043274\n",
      "val_loss: 0.2789365351200104\n",
      "train_loss: 0.2984943389892578\n",
      "val_loss: 0.2765750288963318\n",
      "train_loss: 0.29355794191360474\n",
      "val_loss: 0.27417701482772827\n",
      "train_loss: 0.29450523853302\n",
      "val_loss: 0.2717878818511963\n",
      "train_loss: 0.29292821884155273\n",
      "val_loss: 0.2693956792354584\n",
      "train_loss: 0.28656667470932007\n",
      "val_loss: 0.2670050859451294\n",
      "train_loss: 0.2855910658836365\n",
      "val_loss: 0.2646179795265198\n",
      "train_loss: 0.28498539328575134\n",
      "val_loss: 0.2622314989566803\n",
      "train_loss: 0.28281837701797485\n",
      "val_loss: 0.25985392928123474\n",
      "train_loss: 0.2775932550430298\n",
      "val_loss: 0.2574814260005951\n",
      "train_loss: 0.2772584557533264\n",
      "val_loss: 0.25511634349823\n",
      "train_loss: 0.2737967371940613\n",
      "val_loss: 0.2527833580970764\n",
      "train_loss: 0.27111688256263733\n",
      "val_loss: 0.25036394596099854\n",
      "train_loss: 0.27027052640914917\n",
      "val_loss: 0.24797317385673523\n",
      "train_loss: 0.2673930823802948\n",
      "val_loss: 0.24557551741600037\n",
      "train_loss: 0.26811233162879944\n",
      "val_loss: 0.24318024516105652\n",
      "train_loss: 0.2623640298843384\n",
      "val_loss: 0.24080823361873627\n",
      "train_loss: 0.25832992792129517\n",
      "val_loss: 0.2384602427482605\n",
      "train_loss: 0.2562294602394104\n",
      "val_loss: 0.23587431013584137\n",
      "train_loss: 0.2578238844871521\n",
      "val_loss: 0.23298826813697815\n",
      "train_loss: 0.2544918358325958\n",
      "val_loss: 0.23068982362747192\n",
      "train_loss: 0.24921199679374695\n",
      "val_loss: 0.22823195159435272\n",
      "train_loss: 0.24754318594932556\n",
      "val_loss: 0.22582228481769562\n",
      "train_loss: 0.24591299891471863\n",
      "val_loss: 0.22333842515945435\n",
      "train_loss: 0.2438805103302002\n",
      "val_loss: 0.22086599469184875\n",
      "train_loss: 0.24230551719665527\n",
      "val_loss: 0.21836289763450623\n",
      "train_loss: 0.2379833459854126\n",
      "val_loss: 0.21587535738945007\n",
      "train_loss: 0.23681573569774628\n",
      "val_loss: 0.21340106427669525\n",
      "train_loss: 0.23437824845314026\n",
      "val_loss: 0.21092292666435242\n",
      "train_loss: 0.22911155223846436\n",
      "val_loss: 0.20846445858478546\n",
      "train_loss: 0.22849729657173157\n",
      "val_loss: 0.20599225163459778\n",
      "train_loss: 0.2279132902622223\n",
      "val_loss: 0.20347781479358673\n",
      "train_loss: 0.22533489763736725\n",
      "val_loss: 0.20099106431007385\n",
      "train_loss: 0.22125492990016937\n",
      "val_loss: 0.19819021224975586\n",
      "train_loss: 0.21926528215408325\n",
      "val_loss: 0.19565251469612122\n",
      "train_loss: 0.2155182808637619\n",
      "val_loss: 0.19312354922294617\n",
      "train_loss: 0.21455951035022736\n",
      "val_loss: 0.19054019451141357\n",
      "train_loss: 0.21051661670207977\n",
      "val_loss: 0.18802157044410706\n",
      "train_loss: 0.21046924591064453\n",
      "val_loss: 0.1854918897151947\n",
      "train_loss: 0.20703169703483582\n",
      "val_loss: 0.18298882246017456\n",
      "train_loss: 0.20559582114219666\n",
      "val_loss: 0.1803981065750122\n",
      "train_loss: 0.1989276111125946\n",
      "val_loss: 0.17781664431095123\n",
      "train_loss: 0.1972264051437378\n",
      "val_loss: 0.17522279918193817\n",
      "train_loss: 0.19599077105522156\n",
      "val_loss: 0.1726209968328476\n",
      "train_loss: 0.19604632258415222\n",
      "val_loss: 0.170048788189888\n",
      "train_loss: 0.18980710208415985\n",
      "val_loss: 0.1674978882074356\n",
      "train_loss: 0.18507547676563263\n",
      "val_loss: 0.16493727266788483\n",
      "train_loss: 0.18666742742061615\n",
      "val_loss: 0.16238686442375183\n",
      "train_loss: 0.18511603772640228\n",
      "val_loss: 0.15984384715557098\n",
      "train_loss: 0.18212062120437622\n",
      "val_loss: 0.15730862319469452\n",
      "train_loss: 0.17613017559051514\n",
      "val_loss: 0.1547737419605255\n",
      "train_loss: 0.1774011254310608\n",
      "val_loss: 0.1522415429353714\n",
      "train_loss: 0.17508064210414886\n",
      "val_loss: 0.149675190448761\n",
      "train_loss: 0.1715390384197235\n",
      "val_loss: 0.14694975316524506\n",
      "train_loss: 0.1696750819683075\n",
      "val_loss: 0.1443817913532257\n",
      "train_loss: 0.16302542388439178\n",
      "val_loss: 0.14181743562221527\n",
      "train_loss: 0.16276268661022186\n",
      "val_loss: 0.13926294445991516\n",
      "train_loss: 0.1626119613647461\n",
      "val_loss: 0.13671334087848663\n",
      "train_loss: 0.1586536169052124\n",
      "val_loss: 0.13416869938373566\n",
      "train_loss: 0.15488532185554504\n",
      "val_loss: 0.13161705434322357\n",
      "train_loss: 0.15279395878314972\n",
      "val_loss: 0.12907995283603668\n",
      "train_loss: 0.14889472723007202\n",
      "val_loss: 0.12659941613674164\n",
      "train_loss: 0.15105508267879486\n",
      "val_loss: 0.12399376183748245\n",
      "train_loss: 0.1433115005493164\n",
      "val_loss: 0.12142696976661682\n",
      "train_loss: 0.1448492407798767\n",
      "val_loss: 0.11886819452047348\n",
      "train_loss: 0.1410217583179474\n",
      "val_loss: 0.11628971993923187\n",
      "train_loss: 0.13810963928699493\n",
      "val_loss: 0.11357070505619049\n",
      "train_loss: 0.1360369473695755\n",
      "val_loss: 0.11096598207950592\n",
      "train_loss: 0.13186852633953094\n",
      "val_loss: 0.10835174471139908\n",
      "train_loss: 0.12882059812545776\n",
      "val_loss: 0.10574045777320862\n",
      "train_loss: 0.12859949469566345\n",
      "val_loss: 0.1031380370259285\n",
      "train_loss: 0.12795673310756683\n",
      "val_loss: 0.10051625221967697\n",
      "train_loss: 0.12252125889062881\n",
      "val_loss: 0.09790866822004318\n",
      "train_loss: 0.11858426034450531\n",
      "val_loss: 0.09531456977128983\n",
      "train_loss: 0.11734765768051147\n",
      "val_loss: 0.09272423386573792\n",
      "train_loss: 0.11383030563592911\n",
      "val_loss: 0.09012900292873383\n",
      "train_loss: 0.1114097535610199\n",
      "val_loss: 0.08751843124628067\n",
      "train_loss: 0.11590714752674103\n",
      "val_loss: 0.08449795097112656\n",
      "train_loss: 0.10889642685651779\n",
      "val_loss: 0.08154387772083282\n",
      "train_loss: 0.10516133904457092\n",
      "val_loss: 0.07872673124074936\n",
      "train_loss: 0.10089021176099777\n",
      "val_loss: 0.0759839341044426\n",
      "train_loss: 0.09966657310724258\n",
      "val_loss: 0.07334885001182556\n",
      "train_loss: 0.10031113028526306\n",
      "val_loss: 0.07076554000377655\n",
      "train_loss: 0.09492851048707962\n",
      "val_loss: 0.06818350404500961\n",
      "train_loss: 0.0920710489153862\n",
      "val_loss: 0.06562105566263199\n",
      "train_loss: 0.09211110323667526\n",
      "val_loss: 0.06306292116641998\n",
      "train_loss: 0.08635631948709488\n",
      "val_loss: 0.06052790954709053\n",
      "train_loss: 0.0862184390425682\n",
      "val_loss: 0.05765600502490997\n",
      "train_loss: 0.0821276307106018\n",
      "val_loss: 0.05501492694020271\n",
      "train_loss: 0.08165068179368973\n",
      "val_loss: 0.05246240645647049\n",
      "train_loss: 0.08087104558944702\n",
      "val_loss: 0.04996240884065628\n",
      "train_loss: 0.07815231382846832\n",
      "val_loss: 0.04753802716732025\n",
      "train_loss: 0.07154687494039536\n",
      "val_loss: 0.0452011302113533\n",
      "train_loss: 0.07166992872953415\n",
      "val_loss: 0.042710185050964355\n",
      "train_loss: 0.07208491861820221\n",
      "val_loss: 0.04035656526684761\n",
      "train_loss: 0.06653594970703125\n",
      "val_loss: 0.03816862776875496\n",
      "train_loss: 0.06741482764482498\n",
      "val_loss: 0.035947829484939575\n",
      "train_loss: 0.06552349776029587\n",
      "val_loss: 0.03378336504101753\n",
      "train_loss: 0.06316802650690079\n",
      "val_loss: 0.03182461857795715\n",
      "train_loss: 0.06089692935347557\n",
      "val_loss: 0.029935002326965332\n",
      "train_loss: 0.05831322446465492\n",
      "val_loss: 0.028185395523905754\n",
      "train_loss: 0.05869077146053314\n",
      "val_loss: 0.026560429483652115\n",
      "train_loss: 0.05669303610920906\n",
      "val_loss: 0.025091199204325676\n",
      "train_loss: 0.054793793708086014\n",
      "val_loss: 0.023722650483250618\n",
      "train_loss: 0.054922498762607574\n",
      "val_loss: 0.02252385765314102\n",
      "train_loss: 0.05346384271979332\n",
      "val_loss: 0.02146308124065399\n",
      "train_loss: 0.052552368491888046\n",
      "val_loss: 0.02052321657538414\n",
      "train_loss: 0.04444540664553642\n",
      "val_loss: 0.019739292562007904\n",
      "train_loss: 0.04785466939210892\n",
      "val_loss: 0.019069163128733635\n",
      "train_loss: 0.04924986511468887\n",
      "val_loss: 0.0185175072401762\n",
      "train_loss: 0.048361048102378845\n",
      "val_loss: 0.01811869628727436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type       | Params\n",
      "--------------------------------------------\n",
      "0 | activ1       | Hardshrink | 0     \n",
      "1 | lstm         | LSTM       | 574 K \n",
      "2 | dropout1     | Dropout    | 0     \n",
      "3 | linear_final | Linear     | 369   \n",
      "4 | loss         | L1Loss     | 0     \n",
      "5 | loss_sec     | MAPE       | 0     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.0018486976623535\n",
      "val_loss: 0.9875348210334778\n",
      "train_loss: 0.9871170520782471\n",
      "val_loss: 0.9751201868057251\n",
      "train_loss: 0.9758419990539551\n",
      "val_loss: 0.9614101648330688\n",
      "train_loss: 0.9602667093276978\n",
      "val_loss: 0.9502046704292297\n",
      "train_loss: 0.9511465430259705\n",
      "val_loss: 0.9404923319816589\n",
      "train_loss: 0.9403282403945923\n",
      "val_loss: 0.9360724687576294\n",
      "train_loss: 0.9354590177536011\n",
      "val_loss: 0.9291536211967468\n",
      "train_loss: 0.9295992255210876\n",
      "val_loss: 0.923324465751648\n",
      "train_loss: 0.9234257340431213\n",
      "val_loss: 0.9174749255180359\n",
      "train_loss: 0.9178574681282043\n",
      "val_loss: 0.9118058085441589\n",
      "train_loss: 0.9118275046348572\n",
      "val_loss: 0.9069279432296753\n",
      "train_loss: 0.9072725772857666\n",
      "val_loss: 0.8996405601501465\n",
      "train_loss: 0.9005777835845947\n",
      "val_loss: 0.8890016674995422\n",
      "train_loss: 0.8893373608589172\n",
      "val_loss: 0.8802355527877808\n",
      "train_loss: 0.8809487223625183\n",
      "val_loss: 0.871670126914978\n",
      "train_loss: 0.8729135990142822\n",
      "val_loss: 0.8617748022079468\n",
      "train_loss: 0.8636147379875183\n",
      "val_loss: 0.8548731803894043\n",
      "train_loss: 0.8556368947029114\n",
      "val_loss: 0.8494598865509033\n",
      "train_loss: 0.8495139479637146\n",
      "val_loss: 0.8446187376976013\n",
      "train_loss: 0.8436267375946045\n",
      "val_loss: 0.8387085199356079\n",
      "train_loss: 0.8386937975883484\n",
      "val_loss: 0.8314493894577026\n",
      "train_loss: 0.8309547305107117\n",
      "val_loss: 0.8244930505752563\n",
      "train_loss: 0.8228266835212708\n",
      "val_loss: 0.8172182440757751\n",
      "train_loss: 0.8173685073852539\n",
      "val_loss: 0.8103278279304504\n",
      "train_loss: 0.8100281953811646\n",
      "val_loss: 0.8056931495666504\n",
      "train_loss: 0.8071208000183105\n",
      "val_loss: 0.8006312847137451\n",
      "train_loss: 0.7999715805053711\n",
      "val_loss: 0.7923611402511597\n",
      "train_loss: 0.7939382195472717\n",
      "val_loss: 0.7853378057479858\n",
      "train_loss: 0.7857657074928284\n",
      "val_loss: 0.7795938849449158\n",
      "train_loss: 0.7792474031448364\n",
      "val_loss: 0.7699236273765564\n",
      "train_loss: 0.7699189782142639\n",
      "val_loss: 0.7644293904304504\n",
      "train_loss: 0.7649747729301453\n",
      "val_loss: 0.7578033208847046\n",
      "train_loss: 0.7584775686264038\n",
      "val_loss: 0.750288724899292\n",
      "train_loss: 0.7520653605461121\n",
      "val_loss: 0.7440140843391418\n",
      "train_loss: 0.7453333139419556\n",
      "val_loss: 0.7389581799507141\n",
      "train_loss: 0.7378020286560059\n",
      "val_loss: 0.7352059483528137\n",
      "train_loss: 0.7350348234176636\n",
      "val_loss: 0.7264220714569092\n",
      "train_loss: 0.7271378040313721\n",
      "val_loss: 0.7187350392341614\n",
      "train_loss: 0.7197701930999756\n",
      "val_loss: 0.7130873799324036\n",
      "train_loss: 0.7127642035484314\n",
      "val_loss: 0.7080018520355225\n",
      "train_loss: 0.7087635397911072\n",
      "val_loss: 0.6997851133346558\n",
      "train_loss: 0.6996287703514099\n",
      "val_loss: 0.6944930553436279\n",
      "train_loss: 0.6962218284606934\n",
      "val_loss: 0.6894596815109253\n",
      "train_loss: 0.6904420256614685\n",
      "val_loss: 0.6853209733963013\n",
      "train_loss: 0.6848863959312439\n",
      "val_loss: 0.6804962158203125\n",
      "train_loss: 0.6790632605552673\n",
      "val_loss: 0.6747867465019226\n",
      "train_loss: 0.6736943125724792\n",
      "val_loss: 0.6693695187568665\n",
      "train_loss: 0.6696098446846008\n",
      "val_loss: 0.6608784794807434\n",
      "train_loss: 0.66253662109375\n",
      "val_loss: 0.6543003916740417\n",
      "train_loss: 0.6557528376579285\n",
      "val_loss: 0.648026168346405\n",
      "train_loss: 0.6503280401229858\n",
      "val_loss: 0.6415491104125977\n",
      "train_loss: 0.6418370604515076\n",
      "val_loss: 0.6364537477493286\n",
      "train_loss: 0.6373199820518494\n",
      "val_loss: 0.6318516731262207\n",
      "train_loss: 0.6327629685401917\n",
      "val_loss: 0.6261565089225769\n",
      "train_loss: 0.6280446648597717\n",
      "val_loss: 0.6203956604003906\n",
      "train_loss: 0.6218562722206116\n",
      "val_loss: 0.6138373017311096\n",
      "train_loss: 0.6162024736404419\n",
      "val_loss: 0.6085938811302185\n",
      "train_loss: 0.6116762161254883\n",
      "val_loss: 0.6023665070533752\n",
      "train_loss: 0.6036837100982666\n",
      "val_loss: 0.5968436002731323\n",
      "train_loss: 0.5982674360275269\n",
      "val_loss: 0.5918367505073547\n",
      "train_loss: 0.5939422249794006\n",
      "val_loss: 0.5872142314910889\n",
      "train_loss: 0.5883116126060486\n",
      "val_loss: 0.5809919238090515\n",
      "train_loss: 0.5826815962791443\n",
      "val_loss: 0.5742640495300293\n",
      "train_loss: 0.5764826536178589\n",
      "val_loss: 0.5671019554138184\n",
      "train_loss: 0.5705864429473877\n",
      "val_loss: 0.561804473400116\n",
      "train_loss: 0.5646492838859558\n",
      "val_loss: 0.5559484362602234\n",
      "train_loss: 0.5604420304298401\n",
      "val_loss: 0.5502448081970215\n",
      "train_loss: 0.551322877407074\n",
      "val_loss: 0.5442666411399841\n",
      "train_loss: 0.5469950437545776\n",
      "val_loss: 0.5392955541610718\n",
      "train_loss: 0.5411521196365356\n",
      "val_loss: 0.5340668559074402\n",
      "train_loss: 0.5362451672554016\n",
      "val_loss: 0.5265538096427917\n",
      "train_loss: 0.5290600061416626\n",
      "val_loss: 0.5207621455192566\n",
      "train_loss: 0.5211123824119568\n",
      "val_loss: 0.5153205394744873\n",
      "train_loss: 0.5157172679901123\n",
      "val_loss: 0.5096924304962158\n",
      "train_loss: 0.5128775238990784\n",
      "val_loss: 0.5033799409866333\n",
      "train_loss: 0.5052656531333923\n",
      "val_loss: 0.4977475106716156\n",
      "train_loss: 0.499957799911499\n",
      "val_loss: 0.49272024631500244\n",
      "train_loss: 0.49617189168930054\n",
      "val_loss: 0.4864906072616577\n",
      "train_loss: 0.49028852581977844\n",
      "val_loss: 0.48108145594596863\n",
      "train_loss: 0.4827038645744324\n",
      "val_loss: 0.4758506119251251\n",
      "train_loss: 0.48067373037338257\n",
      "val_loss: 0.4706817865371704\n",
      "train_loss: 0.47361287474632263\n",
      "val_loss: 0.4655061364173889\n",
      "train_loss: 0.4685857594013214\n",
      "val_loss: 0.46013885736465454\n",
      "train_loss: 0.46294105052948\n",
      "val_loss: 0.45494207739830017\n",
      "train_loss: 0.4573369026184082\n",
      "val_loss: 0.44980159401893616\n",
      "train_loss: 0.45197829604148865\n",
      "val_loss: 0.44470953941345215\n",
      "train_loss: 0.4480387270450592\n",
      "val_loss: 0.4394944906234741\n",
      "train_loss: 0.443180650472641\n",
      "val_loss: 0.4342944622039795\n",
      "train_loss: 0.4363597333431244\n",
      "val_loss: 0.42876243591308594\n",
      "train_loss: 0.43135637044906616\n",
      "val_loss: 0.42267870903015137\n",
      "train_loss: 0.4250362515449524\n",
      "val_loss: 0.4171423316001892\n",
      "train_loss: 0.42051413655281067\n",
      "val_loss: 0.4106996953487396\n",
      "train_loss: 0.41318973898887634\n",
      "val_loss: 0.4042690694332123\n",
      "train_loss: 0.40833166241645813\n",
      "val_loss: 0.3986942768096924\n",
      "train_loss: 0.40072518587112427\n",
      "val_loss: 0.3933713138103485\n",
      "train_loss: 0.3956155776977539\n",
      "val_loss: 0.3878757953643799\n",
      "train_loss: 0.38864392042160034\n",
      "val_loss: 0.38293197751045227\n",
      "train_loss: 0.38577109575271606\n",
      "val_loss: 0.37720802426338196\n",
      "train_loss: 0.37890270352363586\n",
      "val_loss: 0.371675968170166\n",
      "train_loss: 0.37466901540756226\n",
      "val_loss: 0.3661665618419647\n",
      "train_loss: 0.3699638247489929\n",
      "val_loss: 0.36041510105133057\n",
      "train_loss: 0.3642130494117737\n",
      "val_loss: 0.35493800044059753\n",
      "train_loss: 0.35961416363716125\n",
      "val_loss: 0.3495962619781494\n",
      "train_loss: 0.3530581593513489\n",
      "val_loss: 0.3443332016468048\n",
      "train_loss: 0.3473604619503021\n",
      "val_loss: 0.33913081884384155\n",
      "train_loss: 0.341734379529953\n",
      "val_loss: 0.33394455909729004\n",
      "train_loss: 0.337423712015152\n",
      "val_loss: 0.3288075625896454\n",
      "train_loss: 0.33262738585472107\n",
      "val_loss: 0.32362446188926697\n",
      "train_loss: 0.3264767825603485\n",
      "val_loss: 0.3184446096420288\n",
      "train_loss: 0.3232819437980652\n",
      "val_loss: 0.3121711015701294\n",
      "train_loss: 0.316301167011261\n",
      "val_loss: 0.30532029271125793\n",
      "train_loss: 0.3091583847999573\n",
      "val_loss: 0.2996697723865509\n",
      "train_loss: 0.304735392332077\n",
      "val_loss: 0.2941761612892151\n",
      "train_loss: 0.29830288887023926\n",
      "val_loss: 0.28868016600608826\n",
      "train_loss: 0.29280373454093933\n",
      "val_loss: 0.28329843282699585\n",
      "train_loss: 0.2879977822303772\n",
      "val_loss: 0.2782124876976013\n",
      "train_loss: 0.280938982963562\n",
      "val_loss: 0.2736230194568634\n",
      "train_loss: 0.2786088287830353\n",
      "val_loss: 0.2674732208251953\n",
      "train_loss: 0.2698841094970703\n",
      "val_loss: 0.2619287371635437\n",
      "train_loss: 0.2665500044822693\n",
      "val_loss: 0.2565896511077881\n",
      "train_loss: 0.26191842555999756\n",
      "val_loss: 0.2511991560459137\n",
      "train_loss: 0.256186842918396\n",
      "val_loss: 0.2458695024251938\n",
      "train_loss: 0.25115078687667847\n",
      "val_loss: 0.24066364765167236\n",
      "train_loss: 0.24533739686012268\n",
      "val_loss: 0.23540519177913666\n",
      "train_loss: 0.2374633252620697\n",
      "val_loss: 0.23023656010627747\n",
      "train_loss: 0.23370695114135742\n",
      "val_loss: 0.22510111331939697\n",
      "train_loss: 0.22914548218250275\n",
      "val_loss: 0.21992982923984528\n",
      "train_loss: 0.2232552021741867\n",
      "val_loss: 0.21475446224212646\n",
      "train_loss: 0.21885447204113007\n",
      "val_loss: 0.20975381135940552\n",
      "train_loss: 0.2113279402256012\n",
      "val_loss: 0.20454370975494385\n",
      "train_loss: 0.2112027406692505\n",
      "val_loss: 0.19942648708820343\n",
      "train_loss: 0.20482565462589264\n",
      "val_loss: 0.19433169066905975\n",
      "train_loss: 0.20006005465984344\n",
      "val_loss: 0.18922121822834015\n",
      "train_loss: 0.19203504920005798\n",
      "val_loss: 0.18408596515655518\n",
      "train_loss: 0.18890705704689026\n",
      "val_loss: 0.17895030975341797\n",
      "train_loss: 0.18619626760482788\n",
      "val_loss: 0.17385216057300568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.1776687055826187\n",
      "val_loss: 0.16872437298297882\n",
      "train_loss: 0.173730731010437\n",
      "val_loss: 0.1635708510875702\n",
      "train_loss: 0.1674998551607132\n",
      "val_loss: 0.15828943252563477\n",
      "train_loss: 0.16468575596809387\n",
      "val_loss: 0.1525946855545044\n",
      "train_loss: 0.15523210167884827\n",
      "val_loss: 0.14722979068756104\n",
      "train_loss: 0.15002857148647308\n",
      "val_loss: 0.1424773931503296\n",
      "train_loss: 0.14667123556137085\n",
      "val_loss: 0.13643305003643036\n",
      "train_loss: 0.14265654981136322\n",
      "val_loss: 0.13121818006038666\n",
      "train_loss: 0.13432680070400238\n",
      "val_loss: 0.12601333856582642\n",
      "train_loss: 0.13016115128993988\n",
      "val_loss: 0.12084408104419708\n",
      "train_loss: 0.1264244168996811\n",
      "val_loss: 0.11568260192871094\n",
      "train_loss: 0.1228671744465828\n",
      "val_loss: 0.11052118241786957\n",
      "train_loss: 0.11986715346574783\n",
      "val_loss: 0.10534261167049408\n",
      "train_loss: 0.10596872866153717\n",
      "val_loss: 0.1001676470041275\n",
      "train_loss: 0.1048482283949852\n",
      "val_loss: 0.0949346274137497\n",
      "train_loss: 0.1004151999950409\n",
      "val_loss: 0.08968725800514221\n",
      "train_loss: 0.0976567417383194\n",
      "val_loss: 0.08446575701236725\n",
      "train_loss: 0.09072668105363846\n",
      "val_loss: 0.07932420074939728\n",
      "train_loss: 0.08799827098846436\n",
      "val_loss: 0.0742526575922966\n",
      "train_loss: 0.08287995308637619\n",
      "val_loss: 0.06926767528057098\n",
      "train_loss: 0.07469216734170914\n",
      "val_loss: 0.06419877707958221\n",
      "train_loss: 0.07373297959566116\n",
      "val_loss: 0.059293508529663086\n",
      "train_loss: 0.06661686301231384\n",
      "val_loss: 0.054529838263988495\n",
      "train_loss: 0.06453926116228104\n",
      "val_loss: 0.04984794184565544\n",
      "train_loss: 0.062048304826021194\n",
      "val_loss: 0.045265618711709976\n",
      "train_loss: 0.05872475355863571\n",
      "val_loss: 0.04082325100898743\n",
      "train_loss: 0.05656192824244499\n",
      "val_loss: 0.03672843426465988\n",
      "train_loss: 0.052540555596351624\n",
      "val_loss: 0.03305758908390999\n",
      "train_loss: 0.05012790486216545\n",
      "val_loss: 0.029819872230291367\n",
      "train_loss: 0.04522830247879028\n",
      "val_loss: 0.02697443962097168\n",
      "train_loss: 0.0474228598177433\n",
      "val_loss: 0.02458556741476059\n",
      "train_loss: 0.04664110019803047\n",
      "val_loss: 0.02266155555844307\n",
      "train_loss: 0.04525240138173103\n",
      "val_loss: 0.021176911890506744\n",
      "train_loss: 0.04451750963926315\n",
      "val_loss: 0.020090268924832344\n",
      "train_loss: 0.04408111795783043\n",
      "val_loss: 0.019457796588540077\n",
      "train_loss: 0.0424208827316761\n",
      "val_loss: 0.019186612218618393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type       | Params\n",
      "--------------------------------------------\n",
      "0 | activ1       | Hardshrink | 0     \n",
      "1 | lstm         | LSTM       | 574 K \n",
      "2 | dropout1     | Dropout    | 0     \n",
      "3 | linear_final | Linear     | 369   \n",
      "4 | loss         | L1Loss     | 0     \n",
      "5 | loss_sec     | MAPE       | 0     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.0013318061828613\n",
      "val_loss: 0.9912673234939575\n",
      "train_loss: 0.9907552003860474\n",
      "val_loss: 0.982584536075592\n",
      "train_loss: 0.9826605916023254\n",
      "val_loss: 0.9729815721511841\n",
      "train_loss: 0.9714846611022949\n",
      "val_loss: 0.9651374816894531\n",
      "train_loss: 0.9649376273155212\n",
      "val_loss: 0.9583389759063721\n",
      "train_loss: 0.9571725726127625\n",
      "val_loss: 0.9552425146102905\n",
      "train_loss: 0.953680694103241\n",
      "val_loss: 0.9503998756408691\n",
      "train_loss: 0.9494708776473999\n",
      "val_loss: 0.9463188648223877\n",
      "train_loss: 0.9450598955154419\n",
      "val_loss: 0.9422173500061035\n",
      "train_loss: 0.9410568475723267\n",
      "val_loss: 0.9382476806640625\n",
      "train_loss: 0.9367246031761169\n",
      "val_loss: 0.9348347783088684\n",
      "train_loss: 0.9334661960601807\n",
      "val_loss: 0.929734468460083\n",
      "train_loss: 0.9286523461341858\n",
      "val_loss: 0.9222850799560547\n",
      "train_loss: 0.9205818772315979\n",
      "val_loss: 0.9161441326141357\n",
      "train_loss: 0.9145633578300476\n",
      "val_loss: 0.9101440906524658\n",
      "train_loss: 0.9087961912155151\n",
      "val_loss: 0.9032161235809326\n",
      "train_loss: 0.9021281003952026\n",
      "val_loss: 0.8983886241912842\n",
      "train_loss: 0.8964027762413025\n",
      "val_loss: 0.8945995569229126\n",
      "train_loss: 0.8920047283172607\n",
      "val_loss: 0.8912062644958496\n",
      "train_loss: 0.8877862095832825\n",
      "val_loss: 0.8870653510093689\n",
      "train_loss: 0.8842388391494751\n",
      "val_loss: 0.8819878101348877\n",
      "train_loss: 0.8786949515342712\n",
      "val_loss: 0.8771084547042847\n",
      "train_loss: 0.8728516101837158\n",
      "val_loss: 0.8720242381095886\n",
      "train_loss: 0.8689446449279785\n",
      "val_loss: 0.8672022819519043\n",
      "train_loss: 0.8636795878410339\n",
      "val_loss: 0.8639604449272156\n",
      "train_loss: 0.8615823984146118\n",
      "val_loss: 0.8604127764701843\n",
      "train_loss: 0.8564516305923462\n",
      "val_loss: 0.8546208739280701\n",
      "train_loss: 0.8521225452423096\n",
      "val_loss: 0.8497035503387451\n",
      "train_loss: 0.8462698459625244\n",
      "val_loss: 0.8456814885139465\n",
      "train_loss: 0.8415902853012085\n",
      "val_loss: 0.8389095067977905\n",
      "train_loss: 0.834880530834198\n",
      "val_loss: 0.8350609540939331\n",
      "train_loss: 0.8313438296318054\n",
      "val_loss: 0.8304226398468018\n",
      "train_loss: 0.8266892433166504\n",
      "val_loss: 0.8251639008522034\n",
      "train_loss: 0.8220794796943665\n",
      "val_loss: 0.820770263671875\n",
      "train_loss: 0.8172362446784973\n",
      "val_loss: 0.8172276616096497\n",
      "train_loss: 0.811832070350647\n",
      "val_loss: 0.8145996928215027\n",
      "train_loss: 0.8098505139350891\n",
      "val_loss: 0.8084500432014465\n",
      "train_loss: 0.8041922450065613\n",
      "val_loss: 0.8030714988708496\n",
      "train_loss: 0.7988993525505066\n",
      "val_loss: 0.7991183996200562\n",
      "train_loss: 0.7938851118087769\n",
      "val_loss: 0.795559287071228\n",
      "train_loss: 0.7910048365592957\n",
      "val_loss: 0.7898066639900208\n",
      "train_loss: 0.7844383120536804\n",
      "val_loss: 0.7861010432243347\n",
      "train_loss: 0.7819997072219849\n",
      "val_loss: 0.7825762629508972\n",
      "train_loss: 0.7778618931770325\n",
      "val_loss: 0.7796727418899536\n",
      "train_loss: 0.773847758769989\n",
      "val_loss: 0.7762914299964905\n",
      "train_loss: 0.7697049975395203\n",
      "val_loss: 0.7722958326339722\n",
      "train_loss: 0.7658451795578003\n",
      "val_loss: 0.7685058116912842\n",
      "train_loss: 0.7629191875457764\n",
      "val_loss: 0.7625666260719299\n",
      "train_loss: 0.757819652557373\n",
      "val_loss: 0.7579598426818848\n",
      "train_loss: 0.7529633045196533\n",
      "val_loss: 0.753564715385437\n",
      "train_loss: 0.7490527629852295\n",
      "val_loss: 0.749032735824585\n",
      "train_loss: 0.7429667115211487\n",
      "val_loss: 0.7454640865325928\n",
      "train_loss: 0.7397257685661316\n",
      "val_loss: 0.7422411441802979\n",
      "train_loss: 0.7364648580551147\n",
      "val_loss: 0.7382545471191406\n",
      "train_loss: 0.7330787181854248\n",
      "val_loss: 0.7342198491096497\n",
      "train_loss: 0.7286311388015747\n",
      "val_loss: 0.7296338677406311\n",
      "train_loss: 0.7245796322822571\n",
      "val_loss: 0.7259599566459656\n",
      "train_loss: 0.721341609954834\n",
      "val_loss: 0.7215988636016846\n",
      "train_loss: 0.7155829071998596\n",
      "val_loss: 0.7177316546440125\n",
      "train_loss: 0.7117251753807068\n",
      "val_loss: 0.7142241597175598\n",
      "train_loss: 0.7086024880409241\n",
      "val_loss: 0.7109837532043457\n",
      "train_loss: 0.7045630812644958\n",
      "val_loss: 0.7066310048103333\n",
      "train_loss: 0.7005317807197571\n",
      "val_loss: 0.7019222378730774\n",
      "train_loss: 0.6960786581039429\n",
      "val_loss: 0.6969065070152283\n",
      "train_loss: 0.6918361783027649\n",
      "val_loss: 0.69319748878479\n",
      "train_loss: 0.6875905990600586\n",
      "val_loss: 0.6890977025032043\n",
      "train_loss: 0.6845550537109375\n",
      "val_loss: 0.6851051449775696\n",
      "train_loss: 0.6780248284339905\n",
      "val_loss: 0.6809213757514954\n",
      "train_loss: 0.6749009490013123\n",
      "val_loss: 0.6774361729621887\n",
      "train_loss: 0.670717179775238\n",
      "val_loss: 0.6737774610519409\n",
      "train_loss: 0.6672083139419556\n",
      "val_loss: 0.6685178875923157\n",
      "train_loss: 0.6620510220527649\n",
      "val_loss: 0.6644604802131653\n",
      "train_loss: 0.6563493609428406\n",
      "val_loss: 0.6606477499008179\n",
      "train_loss: 0.6524717211723328\n",
      "val_loss: 0.6567069292068481\n",
      "train_loss: 0.6504263877868652\n",
      "val_loss: 0.6522904634475708\n",
      "train_loss: 0.6449465155601501\n",
      "val_loss: 0.6483477354049683\n",
      "train_loss: 0.6411713361740112\n",
      "val_loss: 0.644829511642456\n",
      "train_loss: 0.6384403109550476\n",
      "val_loss: 0.6404695510864258\n",
      "train_loss: 0.6342329382896423\n",
      "val_loss: 0.6366825103759766\n",
      "train_loss: 0.6287740468978882\n",
      "val_loss: 0.633020281791687\n",
      "train_loss: 0.6273309588432312\n",
      "val_loss: 0.6294011473655701\n",
      "train_loss: 0.6222780346870422\n",
      "val_loss: 0.6257779002189636\n",
      "train_loss: 0.6186286807060242\n",
      "val_loss: 0.6220201849937439\n",
      "train_loss: 0.6146000623703003\n",
      "val_loss: 0.6183819770812988\n",
      "train_loss: 0.6105535626411438\n",
      "val_loss: 0.6147830486297607\n",
      "train_loss: 0.6067158579826355\n",
      "val_loss: 0.6112176179885864\n",
      "train_loss: 0.6038984656333923\n",
      "val_loss: 0.607566773891449\n",
      "train_loss: 0.6004178524017334\n",
      "val_loss: 0.6039262413978577\n",
      "train_loss: 0.5955215692520142\n",
      "val_loss: 0.6000536680221558\n",
      "train_loss: 0.5919421315193176\n",
      "val_loss: 0.5957939624786377\n",
      "train_loss: 0.5873887538909912\n",
      "val_loss: 0.591917872428894\n",
      "train_loss: 0.5841662883758545\n",
      "val_loss: 0.587409257888794\n",
      "train_loss: 0.5789106488227844\n",
      "val_loss: 0.5829060673713684\n",
      "train_loss: 0.5753912925720215\n",
      "val_loss: 0.578998863697052\n",
      "train_loss: 0.5699442028999329\n",
      "val_loss: 0.5752705931663513\n",
      "train_loss: 0.5662781000137329\n",
      "val_loss: 0.5714243650436401\n",
      "train_loss: 0.561282753944397\n",
      "val_loss: 0.567962646484375\n",
      "train_loss: 0.5592275261878967\n",
      "val_loss: 0.5639541745185852\n",
      "train_loss: 0.5542946457862854\n",
      "val_loss: 0.5600817203521729\n",
      "train_loss: 0.5512648820877075\n",
      "val_loss: 0.5562241673469543\n",
      "train_loss: 0.5478656888008118\n",
      "val_loss: 0.5521985292434692\n",
      "train_loss: 0.543760359287262\n",
      "val_loss: 0.5483642816543579\n",
      "train_loss: 0.5404728651046753\n",
      "val_loss: 0.5446245074272156\n",
      "train_loss: 0.535741925239563\n",
      "val_loss: 0.5409401655197144\n",
      "train_loss: 0.531653642654419\n",
      "val_loss: 0.5372982025146484\n",
      "train_loss: 0.5276398658752441\n",
      "val_loss: 0.5336676239967346\n",
      "train_loss: 0.5245158076286316\n",
      "val_loss: 0.530070960521698\n",
      "train_loss: 0.5210611820220947\n",
      "val_loss: 0.5264420509338379\n",
      "train_loss: 0.5166676044464111\n",
      "val_loss: 0.5228168964385986\n",
      "train_loss: 0.5143904089927673\n",
      "val_loss: 0.5184233784675598\n",
      "train_loss: 0.5093494057655334\n",
      "val_loss: 0.5136277675628662\n",
      "train_loss: 0.5042564868927002\n",
      "val_loss: 0.5096699595451355\n",
      "train_loss: 0.5010762214660645\n",
      "val_loss: 0.505823016166687\n",
      "train_loss: 0.4964524805545807\n",
      "val_loss: 0.5019749402999878\n",
      "train_loss: 0.49250829219818115\n",
      "val_loss: 0.4982072412967682\n",
      "train_loss: 0.489059180021286\n",
      "val_loss: 0.49464771151542664\n",
      "train_loss: 0.48400092124938965\n",
      "val_loss: 0.49143320322036743\n",
      "train_loss: 0.48234063386917114\n",
      "val_loss: 0.48712801933288574\n",
      "train_loss: 0.47606390714645386\n",
      "val_loss: 0.4832456707954407\n",
      "train_loss: 0.4736836850643158\n",
      "val_loss: 0.4795070290565491\n",
      "train_loss: 0.47034749388694763\n",
      "val_loss: 0.47573307156562805\n",
      "train_loss: 0.46622756123542786\n",
      "val_loss: 0.472001850605011\n",
      "train_loss: 0.4626314043998718\n",
      "val_loss: 0.4683573544025421\n",
      "train_loss: 0.4584519565105438\n",
      "val_loss: 0.4646754562854767\n",
      "train_loss: 0.45278286933898926\n",
      "val_loss: 0.4610564708709717\n",
      "train_loss: 0.450103759765625\n",
      "val_loss: 0.45746076107025146\n",
      "train_loss: 0.4468325674533844\n",
      "val_loss: 0.453840434551239\n",
      "train_loss: 0.4426049292087555\n",
      "val_loss: 0.45021718740463257\n",
      "train_loss: 0.43948492407798767\n",
      "val_loss: 0.4467155933380127\n",
      "train_loss: 0.43404319882392883\n",
      "val_loss: 0.44306817650794983\n",
      "train_loss: 0.4339469373226166\n",
      "val_loss: 0.43948549032211304\n",
      "train_loss: 0.4293611943721771\n",
      "val_loss: 0.4359183609485626\n",
      "train_loss: 0.4259486794471741\n",
      "val_loss: 0.43234026432037354\n",
      "train_loss: 0.42021381855010986\n",
      "val_loss: 0.42874500155448914\n",
      "train_loss: 0.4179368019104004\n",
      "val_loss: 0.4251493811607361\n",
      "train_loss: 0.41601911187171936\n",
      "val_loss: 0.4215797185897827\n",
      "train_loss: 0.4098655581474304\n",
      "val_loss: 0.4179892838001251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.40708988904953003\n",
      "val_loss: 0.4143812954425812\n",
      "train_loss: 0.4026021957397461\n",
      "val_loss: 0.41068482398986816\n",
      "train_loss: 0.4005792737007141\n",
      "val_loss: 0.40669721364974976\n",
      "train_loss: 0.39381590485572815\n",
      "val_loss: 0.40293994545936584\n",
      "train_loss: 0.39005541801452637\n",
      "val_loss: 0.39961206912994385\n",
      "train_loss: 0.3876705467700958\n",
      "val_loss: 0.3953804671764374\n",
      "train_loss: 0.384749174118042\n",
      "val_loss: 0.39172691106796265\n",
      "train_loss: 0.378770112991333\n",
      "val_loss: 0.3880796432495117\n",
      "train_loss: 0.37577709555625916\n",
      "val_loss: 0.3844572603702545\n",
      "train_loss: 0.3730834722518921\n",
      "val_loss: 0.3808410167694092\n",
      "train_loss: 0.37052181363105774\n",
      "val_loss: 0.377221018075943\n",
      "train_loss: 0.36824923753738403\n",
      "val_loss: 0.37358373403549194\n",
      "train_loss: 0.35799440741539\n",
      "val_loss: 0.36993861198425293\n",
      "train_loss: 0.3572700619697571\n",
      "val_loss: 0.3662413954734802\n",
      "train_loss: 0.353965699672699\n",
      "val_loss: 0.3625296950340271\n",
      "train_loss: 0.3518056571483612\n",
      "val_loss: 0.3588229715824127\n",
      "train_loss: 0.3464164733886719\n",
      "val_loss: 0.3551490306854248\n",
      "train_loss: 0.34378349781036377\n",
      "val_loss: 0.35150352120399475\n",
      "train_loss: 0.3405815362930298\n",
      "val_loss: 0.3478330969810486\n",
      "train_loss: 0.33391404151916504\n",
      "val_loss: 0.34417280554771423\n",
      "train_loss: 0.33318784832954407\n",
      "val_loss: 0.34051838517189026\n",
      "train_loss: 0.3259560763835907\n",
      "val_loss: 0.3368668258190155\n",
      "train_loss: 0.3245307207107544\n",
      "val_loss: 0.33322155475616455\n",
      "train_loss: 0.3210413455963135\n",
      "val_loss: 0.3295857012271881\n",
      "train_loss: 0.31752288341522217\n",
      "val_loss: 0.3259751796722412\n",
      "train_loss: 0.3149102032184601\n",
      "val_loss: 0.32235589623451233\n",
      "train_loss: 0.3076286017894745\n",
      "val_loss: 0.31875282526016235\n",
      "train_loss: 0.30459505319595337\n",
      "val_loss: 0.31515413522720337\n",
      "train_loss: 0.2997710108757019\n",
      "val_loss: 0.31156307458877563\n",
      "train_loss: 0.2990208864212036\n",
      "val_loss: 0.3079710602760315\n",
      "train_loss: 0.29472771286964417\n",
      "val_loss: 0.3043861389160156\n",
      "train_loss: 0.29152700304985046\n",
      "val_loss: 0.30079951882362366\n",
      "train_loss: 0.28753650188446045\n",
      "val_loss: 0.2972007989883423\n",
      "train_loss: 0.2813016474246979\n",
      "val_loss: 0.29359886050224304\n",
      "train_loss: 0.2796274423599243\n",
      "val_loss: 0.29001930356025696\n",
      "train_loss: 0.2778286039829254\n",
      "val_loss: 0.28643712401390076\n",
      "train_loss: 0.2708512246608734\n",
      "val_loss: 0.28286606073379517\n",
      "train_loss: 0.2684696316719055\n",
      "val_loss: 0.27929964661598206\n",
      "train_loss: 0.26206696033477783\n",
      "val_loss: 0.27576056122779846\n",
      "train_loss: 0.26045164465904236\n",
      "val_loss: 0.2722108066082001\n",
      "train_loss: 0.2575024664402008\n",
      "val_loss: 0.26864832639694214\n",
      "train_loss: 0.2539741098880768\n",
      "val_loss: 0.26510414481163025\n",
      "train_loss: 0.2534758448600769\n",
      "val_loss: 0.2615492641925812\n",
      "train_loss: 0.24763049185276031\n",
      "val_loss: 0.2579832375049591\n",
      "train_loss: 0.24292871356010437\n",
      "val_loss: 0.2544166147708893\n",
      "train_loss: 0.2415883094072342\n",
      "val_loss: 0.25085771083831787\n",
      "train_loss: 0.23781169950962067\n",
      "val_loss: 0.2472914457321167\n",
      "train_loss: 0.23177692294120789\n",
      "val_loss: 0.2437412589788437\n",
      "train_loss: 0.2287416309118271\n",
      "val_loss: 0.24019582569599152\n",
      "train_loss: 0.2241836041212082\n",
      "val_loss: 0.23662225902080536\n",
      "train_loss: 0.22370880842208862\n",
      "val_loss: 0.23300865292549133\n",
      "train_loss: 0.21696798503398895\n",
      "val_loss: 0.22940948605537415\n",
      "train_loss: 0.21434922516345978\n",
      "val_loss: 0.2257818877696991\n",
      "train_loss: 0.2062601000070572\n",
      "val_loss: 0.22215811908245087\n",
      "train_loss: 0.2053443342447281\n",
      "val_loss: 0.2185467928647995\n",
      "train_loss: 0.2028876692056656\n",
      "val_loss: 0.21494647860527039\n",
      "train_loss: 0.19887381792068481\n",
      "val_loss: 0.21134650707244873\n",
      "train_loss: 0.19542665779590607\n",
      "val_loss: 0.20771901309490204\n",
      "train_loss: 0.19275465607643127\n",
      "val_loss: 0.20408739149570465\n",
      "train_loss: 0.1912984997034073\n",
      "val_loss: 0.20045335590839386\n",
      "train_loss: 0.18515071272850037\n",
      "val_loss: 0.19680184125900269\n",
      "train_loss: 0.17931465804576874\n",
      "val_loss: 0.19314639270305634\n",
      "train_loss: 0.1779956966638565\n",
      "val_loss: 0.18947143852710724\n",
      "train_loss: 0.17288492619991302\n",
      "val_loss: 0.18579179048538208\n",
      "train_loss: 0.17015939950942993\n",
      "val_loss: 0.1821158081293106\n",
      "train_loss: 0.16351404786109924\n",
      "val_loss: 0.17845287919044495\n",
      "train_loss: 0.16256392002105713\n",
      "val_loss: 0.17475266754627228\n",
      "train_loss: 0.15896177291870117\n",
      "val_loss: 0.1711229383945465\n",
      "train_loss: 0.1525767743587494\n",
      "val_loss: 0.16746585071086884\n",
      "train_loss: 0.1500341147184372\n",
      "val_loss: 0.16368654370307922\n",
      "train_loss: 0.14771881699562073\n",
      "val_loss: 0.1600433737039566\n",
      "train_loss: 0.1434977948665619\n",
      "val_loss: 0.15643446147441864\n",
      "train_loss: 0.14224815368652344\n",
      "val_loss: 0.15288612246513367\n",
      "train_loss: 0.13513857126235962\n",
      "val_loss: 0.14916560053825378\n",
      "train_loss: 0.13388586044311523\n",
      "val_loss: 0.14555178582668304\n",
      "train_loss: 0.1291341930627823\n",
      "val_loss: 0.1419428437948227\n",
      "train_loss: 0.12654493749141693\n",
      "val_loss: 0.1383306384086609\n",
      "train_loss: 0.12314827740192413\n",
      "val_loss: 0.13470306992530823\n",
      "train_loss: 0.11583878099918365\n",
      "val_loss: 0.13105270266532898\n",
      "train_loss: 0.11435001343488693\n",
      "val_loss: 0.12742026150226593\n",
      "train_loss: 0.11099670827388763\n",
      "val_loss: 0.12379693984985352\n",
      "train_loss: 0.1068236380815506\n",
      "val_loss: 0.12017923593521118\n",
      "train_loss: 0.10080276429653168\n",
      "val_loss: 0.1165747195482254\n",
      "train_loss: 0.09765497595071793\n",
      "val_loss: 0.11298297345638275\n",
      "train_loss: 0.09567040205001831\n",
      "val_loss: 0.10941420495510101\n",
      "train_loss: 0.09167797118425369\n",
      "val_loss: 0.10586333274841309\n",
      "train_loss: 0.08619453012943268\n",
      "val_loss: 0.10231726616621017\n",
      "train_loss: 0.08604777604341507\n",
      "val_loss: 0.09877724945545197\n",
      "train_loss: 0.08553725481033325\n",
      "val_loss: 0.09522921591997147\n",
      "train_loss: 0.07631891965866089\n",
      "val_loss: 0.09175264090299606\n",
      "train_loss: 0.07578111439943314\n",
      "val_loss: 0.08812352269887924\n",
      "train_loss: 0.07484224438667297\n",
      "val_loss: 0.08459774404764175\n",
      "train_loss: 0.06813309341669083\n",
      "val_loss: 0.08111017197370529\n",
      "train_loss: 0.06869351863861084\n",
      "val_loss: 0.0776776671409607\n",
      "train_loss: 0.06493295729160309\n",
      "val_loss: 0.07430094480514526\n",
      "train_loss: 0.060572680085897446\n",
      "val_loss: 0.07090093940496445\n",
      "train_loss: 0.05842721089720726\n",
      "val_loss: 0.06757360696792603\n",
      "train_loss: 0.060228899121284485\n",
      "val_loss: 0.06432802230119705\n",
      "train_loss: 0.05857212841510773\n",
      "val_loss: 0.061170000582933426\n",
      "train_loss: 0.05346907675266266\n",
      "val_loss: 0.058094631880521774\n",
      "train_loss: 0.0507274866104126\n",
      "val_loss: 0.0551283024251461\n",
      "train_loss: 0.0489986352622509\n",
      "val_loss: 0.05226893723011017\n",
      "train_loss: 0.04609350487589836\n",
      "val_loss: 0.049491580575704575\n",
      "train_loss: 0.04697993025183678\n",
      "val_loss: 0.046253230422735214\n",
      "train_loss: 0.04526001214981079\n",
      "val_loss: 0.04361143335700035\n",
      "train_loss: 0.04436452314257622\n",
      "val_loss: 0.04116971790790558\n",
      "train_loss: 0.04390385374426842\n",
      "val_loss: 0.038846470415592194\n",
      "train_loss: 0.03961765393614769\n",
      "val_loss: 0.036709535866975784\n",
      "train_loss: 0.041800543665885925\n",
      "val_loss: 0.03474719077348709\n",
      "train_loss: 0.04249318316578865\n",
      "val_loss: 0.03289489820599556\n",
      "train_loss: 0.03957061469554901\n",
      "val_loss: 0.031170586124062538\n",
      "train_loss: 0.04060777649283409\n",
      "val_loss: 0.029597332701086998\n",
      "train_loss: 0.04159364849328995\n",
      "val_loss: 0.028235003352165222\n",
      "train_loss: 0.04176482930779457\n",
      "val_loss: 0.027024827897548676\n",
      "train_loss: 0.03803665563464165\n",
      "val_loss: 0.025985337793827057\n",
      "train_loss: 0.041262540966272354\n",
      "val_loss: 0.025136031210422516\n",
      "train_loss: 0.04061194509267807\n",
      "val_loss: 0.02454308606684208\n",
      "train_loss: 0.04122157022356987\n",
      "val_loss: 0.02423063851892948\n",
      "train_loss: 0.04086665064096451\n",
      "val_loss: 0.023911861702799797\n",
      "train_loss: 0.03957996144890785\n",
      "val_loss: 0.02376449480652809\n",
      "train_loss: 0.03831551969051361\n",
      "val_loss: 0.023288914933800697\n",
      "train_loss: 0.04179259017109871\n",
      "val_loss: 0.022937878966331482\n",
      "train_loss: 0.040169745683670044\n",
      "val_loss: 0.0227853711694479\n",
      "train_loss: 0.039959151297807693\n",
      "val_loss: 0.0223868265748024\n",
      "train_loss: 0.0383099690079689\n",
      "val_loss: 0.022180844098329544\n",
      "train_loss: 0.041485559195280075\n",
      "val_loss: 0.022075088694691658\n",
      "train_loss: 0.03840024024248123\n",
      "val_loss: 0.02215069904923439\n",
      "train_loss: 0.04028318449854851\n",
      "val_loss: 0.022211309522390366\n",
      "train_loss: 0.040070027112960815\n",
      "val_loss: 0.022470718249678612\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame(columns = ['B_C2H6', 'B_C3H8', 'B_iC4H10', 'B_nC4H10'])\n",
    "submission['timestamp'] = ts\n",
    "\n",
    "for target in ['B_C2H6', 'B_C3H8', 'B_iC4H10', 'B_nC4H10']:\n",
    "    \n",
    "    mean_best_iter = exp.get_numeric_channels_values(target + '_iters').drop('x', axis = 'columns').iloc[n_trial, 0]\n",
    "    mean_best_iter = round(mean_best_iter)\n",
    "    my_boiii = nn_training(simple_torchpl, X_train, y_train[[target]])\n",
    "    my_boiii.train(min_epochs=mean_best_iter,\n",
    "                   max_epochs=mean_best_iter,\n",
    "                   model_params=params,\n",
    "                   batch_size=batch_size,\n",
    "                   fold=fold,\n",
    "                   val_fold=False)\n",
    "\n",
    "    my_model = my_boiii.trained_model\n",
    "    my_model.eval()\n",
    "\n",
    "    predictions = my_model(torch.from_numpy(X_test).float()).detach().numpy()\n",
    "    submission[target] = predictions\n",
    "    \n",
    "submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune.project.get_experiments(exp_index)[0].log_metric('leaderboard_mape', 3.0315)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "neptune": {
   "notebookId": "6eddcb21-b0fa-4073-a5c6-f26572800a8b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
